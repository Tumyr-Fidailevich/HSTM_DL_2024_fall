{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6241b07b-2e75-44eb-ba94-41b3d668f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b75435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c8a984-377b-4c3f-ac90-94487016693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.PILToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf1233fadfc9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_pixels_to_masks(fname: str, df: pd.DataFrame):\n",
    "    fname_df = df[df['ImageId'] == fname]\n",
    "    masks = np.zeros((256 * 1600, 4), dtype=int) # float32 is V.Imp\n",
    "\n",
    "    for i_row, row in fname_df.iterrows():\n",
    "        cls_id = row['ClassId']\n",
    "        encoded_pixels = row['EncodedPixels']\n",
    "        if encoded_pixels is not np.nan:\n",
    "            pixel_list = list(map(int, encoded_pixels.split(' ')))\n",
    "            for i in range(0, len(pixel_list), 2):\n",
    "                start_pixel = pixel_list[i] - 1\n",
    "                num_pixel = pixel_list[i+1]\n",
    "                masks[start_pixel:(start_pixel+num_pixel), cls_id-1] = 1\n",
    "               \n",
    "    masks = masks.reshape(256, 1600, 4, order='F')\n",
    "\n",
    "    return masks\n",
    "\n",
    "def masks_to_encoded_pixels(masks: np.ndarray):\n",
    "    masks = masks.reshape(256*1600, 4, order='F')\n",
    "    encoded_pixels_list = []\n",
    "    for cls_id in range(4):\n",
    "        cls_mask = masks[:, cls_id]\n",
    "        cls_mask = cls_mask.reshape(256, 1600, order='F')\n",
    "        cls_mask = cls_mask.T.flatten()\n",
    "        prev_pixel = 0\n",
    "        prev_pixel_val = 0\n",
    "        encoded_pixels = []\n",
    "        for i, pixel_val in enumerate(cls_mask):\n",
    "            if pixel_val != prev_pixel_val:\n",
    "                if pixel_val == 1:\n",
    "                    start_pixel = i + 1\n",
    "                    encoded_pixels.append(start_pixel - prev_pixel)\n",
    "                else:\n",
    "                    num_pixel = i - prev_pixel\n",
    "                    encoded_pixels.append(num_pixel)\n",
    "                prev_pixel = i\n",
    "                prev_pixel_val = pixel_val\n",
    "        encoded_pixels_list.append(encoded_pixels)\n",
    "    return encoded_pixels_list # shape: 4x[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3c4cf-4643-486a-8878-0379c60c03d5",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a51d514-96b5-4e00-a098-8d820ffbdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeverstalSteelDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform):\n",
    "        self.df = df.reset_index(drop=True) \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.ImageId[idx]\n",
    "        img_path = os.path.join(self.img_dir, fname)\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(Image.open(img_path).convert('RGB')) \n",
    "        masks = encoded_pixels_to_masks(fname, self.df)\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        masks = torch.tensor(masks, dtype=torch.float32).permute(2, 0, 1)\n",
    "        return fname, img, masks\n",
    "    \n",
    "# collate function if needed\n",
    "def collate_fn(batch_items):\n",
    "    batched_fnames = [item[0] for item in batch_items]\n",
    "    batched_imgs = torch.stack([item[1] for item in batch_items])\n",
    "    batched_masks = torch.stack([item[2] for item in batch_items])\n",
    "    return batched_fnames, batched_imgs, batched_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bc81826579aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SegModel, self).__init__()\n",
    "        self.model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', classes=num_classes, activation=None)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4dbb99-65a4-43b7-bfd0-44b449201197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(preds, targets, smooth=1e-6):\n",
    "    preds = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "    \n",
    "    intersection = (preds * targets).sum()\n",
    "    return (2.0 * intersection) / (preds.sum() + targets.sum() + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a871ea7c-e520-44aa-8765-d7be360d7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path, img_folder_path, batch_size=4, val_split=0.2):\n",
    "    if sample_submission:\n",
    "        df = pd.read_csv(csv_path).sample(frac=0.01, random_state=10)\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    train_df, val_df = train_test_split(df, test_size=val_split, random_state=42)\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = SeverstalSteelDataset(train_df, img_folder_path, transform=transform)\n",
    "    val_dataset = SeverstalSteelDataset(val_df, img_folder_path, transform=transform)\n",
    "    \n",
    "    # Создаем загрузчики\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9886aee35f0139bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(device):\n",
    "    model = SegModel().to(device) \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "    return model, criterion, optimizer, scheduler\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    \n",
    "    model.train()  \n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (fnames, imgs, masks) in enumerate(loader):\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        if(batch_idx % 10 == 0):\n",
    "            print(\"Batch #{0} : [train_loss : {1}]\".format(batch_idx, loss.item()))\n",
    "    # возвращаем средний лосс\n",
    "    return train_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    dice_scores = [[], [], [], []]\n",
    "                                 \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (fnames, imgs, masks) in enumerate(val_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            masks = masks.cpu().numpy()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            if(batch_idx % 10 == 0):\n",
    "                print(\"Batch #{0} : [val_loss : {1}]\".format(batch_idx, loss.item()))\n",
    "            \n",
    "            for i in range(masks.shape[1]):\n",
    "                score = dice_score(preds[:, i], masks[:, i])\n",
    "                dice_scores[i].append(score)\n",
    "            \n",
    "    avg_loss = val_loss / len(loader)\n",
    "    avg_dice = []\n",
    "    for class_dice in dice_scores:  \n",
    "        avg_dice.append(sum(class_dice) / len(class_dice) if class_dice else 0.0)\n",
    "    \n",
    "    return avg_loss, avg_dice\n",
    "\n",
    "def fit(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, score = validate(model, val_loader, criterion, device)\n",
    "        print(\"Epoch #{0}: [val_loss : {1}, train_loss: {2}, dice_score: {3}]\".format(epoch, val_loss, train_loss, score))\n",
    "        scheduler.step(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2c165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_images_dir, device): \n",
    "    model.eval()\n",
    "\n",
    "    # Список для хранения результатов\n",
    "    results = []\n",
    "    \n",
    "    image_ids = [f for f in os.listdir(test_images_dir)]\n",
    "\n",
    "    if sample_submission:\n",
    "        image_ids = image_ids[:10]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image_id in image_ids:\n",
    "            # Чтение изображения\n",
    "            image_path = os.path.join(test_images_dir, image_id)\n",
    "            image = np.array(Image.open(image_path).convert('RGB')) \n",
    "            image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "            \n",
    "            mask = torch.sigmoid(outputs) # Бинаризация\n",
    "            outputs = torch.sigmoid(outputs).squeeze(0).cpu().numpy() # Преобразуем к Numpy\n",
    "            \n",
    "            encoded_pixels = masks_to_encoded_pixels(mask.cpu().numpy()) # Преобразование в EncodedPixels\n",
    "            \n",
    "            for class_id in range(4):\n",
    "                \n",
    "                enc_pixels = \" \".join(str(x) for x in encoded_pixels[class_id])\n",
    "\n",
    "                if encoded_pixels: # Если маска непустая\n",
    "                    results.append({\n",
    "                    'ImageId': image_id,\n",
    "                    'EncodedPixels': encoded_pixels,\n",
    "                    'ClassId': class_id\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results, columns=['ImageId', 'EncodedPixels', 'ClassId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0933c5eb321cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Used device: {0}\".format(device))\n",
    "model, criterion, optimizer, scheduler = init_model(device)\n",
    "train_loader, val_loader = load_data(\"../data/train.csv\", \"../data/train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d273a8-61af-481c-ba55-79540a737f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0 : [train_loss : 0.981880784034729]\n",
      "Batch #10 : [train_loss : 0.9532279968261719]\n",
      "Batch #0 : [val_loss : 0.9860326647758484]\n",
      "Epoch #0: [val_loss : 0.9825904965400696, train_loss: 0.9632567805903298, dice_score: [0.0012831801769974467, 0.0048335821845415065, 0.05597640436691771, 0.0]]\n",
      "Batch #0 : [train_loss : 0.9375742673873901]\n",
      "Batch #10 : [train_loss : 0.9312376379966736]\n",
      "Batch #0 : [val_loss : 0.9408236742019653]\n",
      "Epoch #1: [val_loss : 0.9416815787553787, train_loss: 0.9328219890594482, dice_score: [0.0012216955872585739, 0.005168603432813786, 0.05612621281656001, 0.0]]\n",
      "Batch #0 : [train_loss : 0.917434811592102]\n",
      "Batch #10 : [train_loss : 0.9141151905059814]\n",
      "Batch #0 : [val_loss : 0.8976342678070068]\n",
      "Epoch #2: [val_loss : 0.9043236970901489, train_loss: 0.9151129296847752, dice_score: [0.0012895382267455505, 0.005210473683725723, 0.05685587056135412, 0.0]]\n",
      "Batch #0 : [train_loss : 0.9065769910812378]\n",
      "Batch #10 : [train_loss : 0.9020928144454956]\n",
      "Batch #0 : [val_loss : 0.8771128058433533]\n",
      "Epoch #3: [val_loss : 0.8836134225130081, train_loss: 0.9020119522299085, dice_score: [0.0012925540276112952, 0.005195400057013945, 0.05729335541712022, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8952096104621887]\n",
      "Batch #10 : [train_loss : 0.8891459703445435]\n",
      "Batch #0 : [val_loss : 0.8785319924354553]\n",
      "Epoch #4: [val_loss : 0.8833164274692535, train_loss: 0.8917289802006313, dice_score: [0.0012746121609851248, 0.005111831664436007, 0.056716282417321434, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8844016790390015]\n",
      "Batch #10 : [train_loss : 0.8869959712028503]\n",
      "Batch #0 : [val_loss : 0.8795350193977356]\n",
      "Epoch #5: [val_loss : 0.8803447037935257, train_loss: 0.8830075434276036, dice_score: [0.0012557880839737252, 0.005082117946589005, 0.056572292680700534, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8672016859054565]\n",
      "Batch #10 : [train_loss : 0.872076690196991]\n",
      "Batch #0 : [val_loss : 0.8715370893478394]\n",
      "Epoch #6: [val_loss : 0.8693549931049347, train_loss: 0.8743772719587598, dice_score: [0.0012392754014122777, 0.005090485782013364, 0.05673144977320599, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8729662299156189]\n",
      "Batch #10 : [train_loss : 0.8603618144989014]\n",
      "Batch #0 : [val_loss : 0.8639341592788696]\n",
      "Epoch #7: [val_loss : 0.8623534739017487, train_loss: 0.8664198986121586, dice_score: [0.001204658759370099, 0.005049339945739728, 0.05682481568702296, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8674181699752808]\n",
      "Batch #10 : [train_loss : 0.8557590246200562]\n",
      "Batch #0 : [val_loss : 0.8545690774917603]\n",
      "Epoch #8: [val_loss : 0.8530989587306976, train_loss: 0.8590288630553654, dice_score: [0.0012438813598712314, 0.0050612431245920944, 0.05746940940893165, 0.0]]\n",
      "Batch #0 : [train_loss : 0.8578464388847351]\n",
      "Batch #10 : [train_loss : 0.8543666005134583]\n",
      "Batch #0 : [val_loss : 0.8488563299179077]\n",
      "Epoch #9: [val_loss : 0.8486776649951935, train_loss: 0.8514935416834695, dice_score: [0.00119579682402734, 0.005046102406387237, 0.0569199301343976, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_loader, val_loader, criterion, optimizer, scheduler, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ad6e06-9f05-4381-9972-d0562b8fbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = evaluate(model, \"../data/test_images\", device)\n",
    "submission_df.to_csv(\"my_submission.csv\", index=False)\n",
    "# submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
