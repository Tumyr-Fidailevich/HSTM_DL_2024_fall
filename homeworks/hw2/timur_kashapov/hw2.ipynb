{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6241b07b-2e75-44eb-ba94-41b3d668f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b75435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c8a984-377b-4c3f-ac90-94487016693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.PILToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf1233fadfc9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_pixels_to_masks(fname: str, df: pd.DataFrame):\n",
    "    fname_df = df[df['ImageId'] == fname]\n",
    "    masks = np.zeros((256 * 1600, 4), dtype=int) # float32 is V.Imp\n",
    "\n",
    "    for i_row, row in fname_df.iterrows():\n",
    "        cls_id = row['ClassId']\n",
    "        encoded_pixels = row['EncodedPixels']\n",
    "        if encoded_pixels is not np.nan:\n",
    "            pixel_list = list(map(int, encoded_pixels.split(' ')))\n",
    "            for i in range(0, len(pixel_list), 2):\n",
    "                start_pixel = pixel_list[i] - 1\n",
    "                num_pixel = pixel_list[i+1]\n",
    "                masks[start_pixel:(start_pixel+num_pixel), cls_id-1] = 1\n",
    "               \n",
    "    masks = masks.reshape(256, 1600, 4, order='F')\n",
    "\n",
    "    return masks\n",
    "\n",
    "def masks_to_encoded_pixels(masks: np.ndarray):\n",
    "    masks = masks.reshape(256*1600, 4, order='F')\n",
    "    encoded_pixels_list = []\n",
    "    for cls_id in range(4):\n",
    "        cls_mask = masks[:, cls_id]\n",
    "        cls_mask = cls_mask.reshape(256, 1600, order='F')\n",
    "        cls_mask = cls_mask.T.flatten()\n",
    "        prev_pixel = 0\n",
    "        prev_pixel_val = 0\n",
    "        encoded_pixels = []\n",
    "        for i, pixel_val in enumerate(cls_mask):\n",
    "            if pixel_val != prev_pixel_val:\n",
    "                if pixel_val == 1:\n",
    "                    start_pixel = i + 1\n",
    "                    encoded_pixels.append(start_pixel - prev_pixel)\n",
    "                else:\n",
    "                    num_pixel = i - prev_pixel\n",
    "                    encoded_pixels.append(num_pixel)\n",
    "                prev_pixel = i\n",
    "                prev_pixel_val = pixel_val\n",
    "        encoded_pixels_list.append(encoded_pixels)\n",
    "    return encoded_pixels_list # shape: 4x[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3c4cf-4643-486a-8878-0379c60c03d5",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a51d514-96b5-4e00-a098-8d820ffbdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeverstalSteelDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform):\n",
    "        self.df = df.reset_index(drop=True) \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.ImageId[idx]\n",
    "        img_path = os.path.join(self.img_dir, fname)\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(Image.open(img_path).convert('RGB')) \n",
    "        masks = encoded_pixels_to_masks(fname, self.df)\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        masks = torch.tensor(masks, dtype=torch.float32).permute(2, 0, 1)\n",
    "        return fname, img, masks\n",
    "    \n",
    "# collate function if needed\n",
    "def collate_fn(batch_items):\n",
    "    batched_fnames = [item[0] for item in batch_items]\n",
    "    batched_imgs = torch.stack([item[1] for item in batch_items])\n",
    "    batched_masks = torch.stack([item[2] for item in batch_items])\n",
    "    return batched_fnames, batched_imgs, batched_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6bc81826579aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SegModel, self).__init__()\n",
    "        self.model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', classes=num_classes, activation=None)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4dbb99-65a4-43b7-bfd0-44b449201197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(preds, targets):\n",
    "    intersection = np.sum(preds * targets)\n",
    "    denominator = np.sum(preds) + np.sum(targets)\n",
    "    if denominator == 0:\n",
    "        return 1.0 \n",
    "    return (2 * intersection) / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a871ea7c-e520-44aa-8765-d7be360d7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path, img_folder_path, batch_size=4, val_split=0.2):\n",
    "    if sample_submission:\n",
    "        df = pd.read_csv(csv_path).sample(frac=0.01, random_state=10)\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    train_df, val_df = train_test_split(df, test_size=val_split, random_state=42)\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = SeverstalSteelDataset(train_df, img_folder_path, transform=transform)\n",
    "    val_dataset = SeverstalSteelDataset(val_df, img_folder_path, transform=transform)\n",
    "    \n",
    "    # Создаем загрузчики\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9886aee35f0139bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(device):\n",
    "    model = SegModel().to(device) \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "    return model, criterion, optimizer, scheduler\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    \n",
    "    model.train()  \n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (fnames, imgs, masks) in enumerate(loader):\n",
    "        imgs = imgs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(imgs).cpu()\n",
    "        \n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        if(batch_idx % 10 == 0):\n",
    "            print(\"Batch #{0} : [train_loss : {1}]\".format(batch_idx, loss.item()))\n",
    "    # возвращаем средний лосс\n",
    "    return train_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    dice_scores = [[], [], [], []]\n",
    "                                 \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (fnames, imgs, masks) in enumerate(val_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy()\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            masks = masks.cpu().numpy()\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            if(batch_idx % 10 == 0):\n",
    "                print(\"Batch #{0} : [val_loss : {1}]\".format(batch_idx, loss.item()))\n",
    "                \n",
    "            for idx in range(len(fnames)):\n",
    "                for cls_id in range(masks.shape[1]):\n",
    "                    score = dice_score(preds[idx, cls_id], masks[idx, cls_id])\n",
    "                    dice_scores[cls_id].append(score)\n",
    "            \n",
    "    avg_loss = val_loss / len(loader)\n",
    "    avg_dice = []\n",
    "    for class_dice in dice_scores:  \n",
    "        avg_dice.append(sum(class_dice) / len(class_dice) if class_dice else 0.0)\n",
    "    \n",
    "    return avg_loss, avg_dice\n",
    "\n",
    "def fit(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, score = validate(model, val_loader, criterion, device)\n",
    "        print(\"Epoch #{0}: [val_loss : {1}, train_loss: {2}, dice_score: {3}]\".format(epoch, val_loss, train_loss, score))\n",
    "        scheduler.step(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2c165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_images_dir, device): \n",
    "    model.eval()\n",
    "\n",
    "    # Список для хранения результатов\n",
    "    results = []\n",
    "    \n",
    "    image_ids = [f for f in os.listdir(test_images_dir)]\n",
    "\n",
    "    if sample_submission:\n",
    "        image_ids = image_ids[:10]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image_id in image_ids:\n",
    "            # Чтение изображения\n",
    "            image_path = os.path.join(test_images_dir, image_id)\n",
    "            image = np.array(Image.open(image_path).convert('RGB')) \n",
    "            image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "            \n",
    "            outputs = (torch.sigmoid(outputs) > 0.5).squeeze(0).cpu().numpy() # Преобразуем к Numpy\n",
    "            \n",
    "            encoded_pixels = masks_to_encoded_pixels(outputs) # Преобразование в EncodedPixels\n",
    "            \n",
    "            for cls_id in range(4):\n",
    "                \n",
    "                enc_pixels = \" \".join(str(x) for x in encoded_pixels[cls_id])\n",
    "\n",
    "                if len(encoded_pixels) > 1: # Если маска непустая\n",
    "                    results.append({\n",
    "                    'ImageId': image_id,\n",
    "                    'EncodedPixels': enc_pixels,\n",
    "                    'ClassId': cls_id\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results, columns=['ImageId', 'EncodedPixels', 'ClassId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0933c5eb321cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Used device: {0}\".format(device))\n",
    "model, criterion, optimizer, scheduler = init_model(device)\n",
    "train_loader, val_loader = load_data(\"../data/train.csv\", \"../data/train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d273a8-61af-481c-ba55-79540a737f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0 : [train_loss : 0.7022920250892639]\n",
      "Batch #10 : [train_loss : 0.6257580518722534]\n",
      "Batch #0 : [val_loss : 0.6035407185554504]\n",
      "Epoch #0: [val_loss : 0.606315091252327, train_loss: 0.6518986608300891, dice_score: [0.0004454045352340793, 0.004858804944412608, 0.09041889631620201, 0.0]]\n",
      "Batch #0 : [train_loss : 0.5925085544586182]\n",
      "Batch #10 : [train_loss : 0.563563883304596]\n",
      "Batch #0 : [val_loss : 0.511867880821228]\n",
      "Epoch #1: [val_loss : 0.553706556558609, train_loss: 0.5723726068224225, dice_score: [0.0, 0.0026487719242881133, 0.13906128949095675, 0.0]]\n",
      "Batch #0 : [train_loss : 0.5412086844444275]\n",
      "Batch #10 : [train_loss : 0.5006518363952637]\n",
      "Batch #0 : [val_loss : 0.47662612795829773]\n",
      "Epoch #2: [val_loss : 0.5762616619467735, train_loss: 0.515886447259358, dice_score: [3.3085194375516956e-05, 0.007840662353353145, 0.1570307748368141, 0.0]]\n",
      "Batch #0 : [train_loss : 0.4905337989330292]\n",
      "Batch #10 : [train_loss : 0.4592343270778656]\n",
      "Batch #0 : [val_loss : 0.43709447979927063]\n",
      "Epoch #3: [val_loss : 0.4596644788980484, train_loss: 0.4677314566714423, dice_score: [0.13333333333333333, 0.007333499280221175, 0.23813668287643228, 0.0]]\n",
      "Batch #0 : [train_loss : 0.44465819001197815]\n",
      "Batch #10 : [train_loss : 0.41975975036621094]\n",
      "Batch #0 : [val_loss : 0.407802939414978]\n",
      "Epoch #4: [val_loss : 0.41279352456331253, train_loss: 0.43313893037182943, dice_score: [0.7333333333333333, 0.006549565305591089, 0.25626385732377793, 0.0]]\n",
      "Batch #0 : [train_loss : 0.4155105948448181]\n",
      "Batch #10 : [train_loss : 0.39676812291145325]\n",
      "Batch #0 : [val_loss : 0.37483710050582886]\n",
      "Epoch #5: [val_loss : 0.37835583090782166, train_loss: 0.40333035162517, dice_score: [0.8666666666666667, 0.005789062641117952, 0.21787008330145344, 0.0]]\n",
      "Batch #0 : [train_loss : 0.39566150307655334]\n",
      "Batch #10 : [train_loss : 0.3676599860191345]\n",
      "Batch #0 : [val_loss : 0.3521827757358551]\n",
      "Epoch #6: [val_loss : 0.36565539240837097, train_loss: 0.3762751136507307, dice_score: [0.8, 0.005187395902820888, 0.2405174161633879, 0.0]]\n",
      "Batch #0 : [train_loss : 0.3691088557243347]\n",
      "Batch #10 : [train_loss : 0.35173869132995605]\n",
      "Batch #0 : [val_loss : 0.3314511775970459]\n",
      "Epoch #7: [val_loss : 0.33217594027519226, train_loss: 0.35303373847688946, dice_score: [0.8666666666666667, 0.005450066432884259, 0.25978259892798555, 0.13333333333333333]]\n",
      "Batch #0 : [train_loss : 0.3386036157608032]\n",
      "Batch #10 : [train_loss : 0.32289445400238037]\n",
      "Batch #0 : [val_loss : 0.3209739327430725]\n",
      "Epoch #8: [val_loss : 0.3193403631448746, train_loss: 0.3323785024029868, dice_score: [0.8666666666666667, 0.005753552737625294, 0.2382159837922021, 0.2]]\n",
      "Batch #0 : [train_loss : 0.3247873783111572]\n",
      "Batch #10 : [train_loss : 0.30464208126068115]\n",
      "Batch #0 : [val_loss : 0.2943505048751831]\n",
      "Epoch #9: [val_loss : 0.2953150123357773, train_loss: 0.31241017154284884, dice_score: [0.8666666666666667, 0.008698241462792283, 0.2843993896410505, 0.6]]\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_loader, val_loader, criterion, optimizer, scheduler, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ad6e06-9f05-4381-9972-d0562b8fbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = evaluate(model, \"../data/test_images\", device)\n",
    "submission_df.to_csv(\"my_submission.csv\", index=False)\n",
    "# submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22a250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
